{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 1 - Partie 2 : Inférence de Trajectoires et Interpolation de McCann\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "Dans ce notebook, vous allez :\n",
    "1. Reconstruire des trajectoires en chaînant les couplages OT entre snapshots successifs\n",
    "2. Implémenter l'interpolation de McCann (géodésiques de Wasserstein)\n",
    "3. Comparer les distributions interpolées avec les vraies distributions intermédiaires\n",
    "4. Mesurer l'erreur de reconstruction en fonction du paramètre $\\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ot\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.colors import LogNorm\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from simulation import simulate_sde\n",
    "\n",
    "# Configuration matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rappel : Interpolation de McCann\n",
    "\n",
    "### Définition\n",
    "\n",
    "Étant données deux distributions $\\mu_0$ et $\\mu_1$, et un plan de transport optimal $\\pi^*$, l'**interpolation de McCann** (ou **géodésique de Wasserstein**) au temps $t \\in [0, 1]$ est définie par :\n",
    "\n",
    "$$\n",
    "\\mu_t := \\left[(1-t)X + tY\\right]_\\# \\pi^*\n",
    "$$\n",
    "\n",
    "où $(X, Y) \\sim \\pi^*$ et $f_\\#\\mu$ désigne la mesure image.\n",
    "\n",
    "### Propriété géodésique\n",
    "\n",
    "Cette interpolation est une **géodésique à vitesse constante** pour la distance de Wasserstein-2 :\n",
    "\n",
    "$$\n",
    "W_2(\\mu_s, \\mu_t) = |t - s| \\cdot W_2(\\mu_0, \\mu_1)\n",
    "$$\n",
    "\n",
    "### Interprétation\n",
    "\n",
    "Pour l'inférence de trajectoires, si on a calculé le couplage optimal entre deux snapshots, l'interpolation de McCann nous donne une prédiction naturelle de la distribution intermédiaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données\n",
    "\n",
    "On va générer deux ensembles de données :\n",
    "1. **Snapshots espacés** : pour calculer les couplages OT\n",
    "2. **Snapshots denses** : pour avoir la \"vraie\" distribution intermédiaire à comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de simulation\n",
    "n_particles = 1000\n",
    "dim = 2\n",
    "t0, t1 = 0.0, 1.0\n",
    "dt = 1e-3\n",
    "sigma = 0.5\n",
    "seed = 42\n",
    "\n",
    "# Snapshots espacés (pour calculer OT)\n",
    "n_snapshots_sparse = 6\n",
    "snapshot_times_sparse = np.linspace(t0, t1, n_snapshots_sparse)\n",
    "\n",
    "snapshots_sparse = simulate_sde(\n",
    "    n_particles=n_particles,\n",
    "    dim=dim,\n",
    "    t0=t0,\n",
    "    t1=t1,\n",
    "    dt=dt,\n",
    "    sigma=sigma,\n",
    "    snapshot_times=snapshot_times_sparse,\n",
    "    potential_type='complex',\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Snapshots denses (pour avoir les vraies distributions intermédiaires)\n",
    "n_snapshots_dense = 21\n",
    "snapshot_times_dense = np.linspace(t0, t1, n_snapshots_dense)\n",
    "\n",
    "snapshots_dense = simulate_sde(\n",
    "    n_particles=n_particles,\n",
    "    dim=dim,\n",
    "    t0=t0,\n",
    "    t1=t1,\n",
    "    dt=dt,\n",
    "    sigma=sigma,\n",
    "    snapshot_times=snapshot_times_dense,\n",
    "    potential_type='complex',\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(f\"Snapshots espacés: {len(snapshots_sparse)} aux temps {snapshot_times_sparse}\")\n",
    "print(f\"Snapshots denses: {len(snapshots_dense)} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calcul des couplages entre snapshots consécutifs\n",
    "\n",
    "On va d'abord calculer les couplages OT entropique entre chaque paire de snapshots consécutifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ot_coupling(X_source, X_target, epsilon):\n",
    "    \"\"\"\n",
    "    Calcule le couplage OT entropique entre deux distributions empiriques.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_source : ndarray, shape (n_source, d)\n",
    "        Particules sources\n",
    "    X_target : ndarray, shape (n_target, d)\n",
    "        Particules cibles\n",
    "    epsilon : float\n",
    "        Paramètre de régularisation entropique\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    gamma : ndarray, shape (n_source, n_target)\n",
    "        Plan de transport optimal\n",
    "    \"\"\"\n",
    "    # TODO: Implémenter cette fonction\n",
    "    # Hint: Créer les distributions uniformes a et b\n",
    "    # Hint: Calculer la matrice de coût C\n",
    "    # Hint: Utiliser ot.sinkhorn\n",
    "    \n",
    "    n_source = len(X_source)\n",
    "    n_target = len(X_target)\n",
    "    \n",
    "    a = # VOTRE CODE ICI\n",
    "    b = # VOTRE CODE ICI\n",
    "    \n",
    "    C = # VOTRE CODE ICI\n",
    "    \n",
    "    gamma = # VOTRE CODE ICI\n",
    "    \n",
    "    return gamma\n",
    "\n",
    "# Calculer tous les couplages\n",
    "times_sparse = sorted(snapshots_sparse.keys())\n",
    "epsilon_theory = sigma * (times_sparse[1] - times_sparse[0])\n",
    "\n",
    "print(f\"Paramètre de régularisation (théorique): ε = {epsilon_theory:.4f}\")\n",
    "print(\"\\nCalcul des couplages...\")\n",
    "\n",
    "couplings = {}\n",
    "for i in range(len(times_sparse) - 1):\n",
    "    t_start = times_sparse[i]\n",
    "    t_end = times_sparse[i + 1]\n",
    "    \n",
    "    X_start = snapshots_sparse[t_start]\n",
    "    X_end = snapshots_sparse[t_end]\n",
    "    \n",
    "    gamma = compute_ot_coupling(X_start, X_end, epsilon_theory)\n",
    "    couplings[(t_start, t_end)] = gamma\n",
    "    \n",
    "    print(f\"  [{t_start:.2f} → {t_end:.2f}] : couplage de forme {gamma.shape}\")\n",
    "\n",
    "print(\"\\n✓ Couplages calculés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inférence de trajectoires par chaînage de couplages\n",
    "\n",
    "Une fois qu'on a les couplages, on peut reconstruire des trajectoires en les chaînant. Pour chaque particule au temps $t_0$, on peut :\n",
    "1. La \"transporter\" au temps $t_1$ selon $\\gamma^*_{t_0, t_1}$\n",
    "2. Puis la transporter au temps $t_2$ selon $\\gamma^*_{t_1, t_2}$\n",
    "3. Etc.\n",
    "\n",
    "En pratique, pour une particule $i$ au temps $t_k$, on échantillonne son image au temps $t_{k+1}$ selon la distribution $\\gamma^*_{t_k, t_{k+1}}(i, \\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trajectories(snapshots_dict, couplings, n_trajectories=100, seed=42):\n",
    "    \"\"\"\n",
    "    Construit des trajectoires en chaînant les couplages OT.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    snapshots_dict : dict\n",
    "        Dictionnaire {temps: array de particules}\n",
    "    couplings : dict\n",
    "        Dictionnaire {(t_start, t_end): matrice de couplage}\n",
    "    n_trajectories : int\n",
    "        Nombre de trajectoires à construire\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trajectories : list of list of ndarray\n",
    "        Liste de trajectoires, chaque trajectoire est une liste de positions\n",
    "    \"\"\"\n",
    "    # TODO: Implémenter le chaînage de couplages\n",
    "    # Hint: Partir de particules aléatoires au temps initial\n",
    "    # Hint: Pour chaque temps, échantillonner la particule suivante selon gamma[current_idx, :]\n",
    "    # Hint: Normaliser la distribution conditionnelle avant d'échantillonner\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    times = sorted(snapshots_dict.keys())\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    trajectories = []\n",
    "    \n",
    "    return trajectories, times\n",
    "\n",
    "# Construire les trajectoires\n",
    "trajectories, times_traj = build_trajectories(\n",
    "    snapshots_sparse, \n",
    "    couplings, \n",
    "    n_trajectories=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Construit {len(trajectories)} trajectoires\")\n",
    "if len(trajectories) > 0:\n",
    "    print(f\"Chaque trajectoire a {len(trajectories[0])} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des trajectoires\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Tracer les trajectoires\n",
    "for traj in trajectories:\n",
    "    traj_array = np.array(traj)\n",
    "    ax.plot(traj_array[:, 0], traj_array[:, 1], 'o-', alpha=0.3, markersize=4, linewidth=1)\n",
    "\n",
    "# Marquer les snapshots\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(times_traj)))\n",
    "for idx, t in enumerate(times_traj):\n",
    "    X = snapshots_sparse[t]\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=[colors[idx]], s=5, alpha=0.1, \n",
    "              label=f't={t:.2f}' if idx in [0, len(times_traj)//2, len(times_traj)-1] else '')\n",
    "\n",
    "ax.set_xlabel('$x_0$')\n",
    "ax.set_ylabel('$x_1$')\n",
    "ax.set_title('Trajectoires inférées par chaînage de couplages OT')\n",
    "ax.legend()\n",
    "ax.axis('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interpolation de McCann\n",
    "\n",
    "### 5.1 Implémentation\n",
    "\n",
    "Pour calculer l'interpolation de McCann entre deux distributions $\\mu_0$ et $\\mu_1$ avec un couplage $\\pi^*$, on doit :\n",
    "\n",
    "1. Échantillonner des paires $(x, y) \\sim \\pi^*$\n",
    "2. Pour chaque paire, calculer le point interpolé : $z_t = (1-t)x + ty$\n",
    "3. La distribution empirique de tous les $z_t$ est notre $\\mu_t$ interpolée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mccann_interpolation(X_source, X_target, gamma, t, n_samples=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Calcule l'interpolation de McCann au temps t entre deux distributions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_source : ndarray, shape (n_source, d)\n",
    "        Particules sources (au temps 0)\n",
    "    X_target : ndarray, shape (n_target, d)\n",
    "        Particules cibles (au temps 1)\n",
    "    gamma : ndarray, shape (n_source, n_target)\n",
    "        Plan de transport optimal\n",
    "    t : float\n",
    "        Temps d'interpolation (entre 0 et 1)\n",
    "    n_samples : int\n",
    "        Nombre d'échantillons à générer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_interp : ndarray, shape (n_samples, d)\n",
    "        Particules interpolées au temps t\n",
    "    \"\"\"\n",
    "    # TODO: Implémenter l'interpolation de McCann\n",
    "    # Hint: Aplatir gamma pour avoir une distribution sur les paires (i,j)\n",
    "    # Hint: Échantillonner n_samples paires selon gamma_flat\n",
    "    # Hint: Convertir les indices plats en indices (i, j)\n",
    "    # Hint: Calculer (1-t) * X_source[i] + t * X_target[j]\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    n_source, n_target = gamma.shape\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    X_interp = None\n",
    "    \n",
    "    return X_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Test sur un intervalle\n",
    "\n",
    "Testons l'interpolation de McCann entre les deux premiers snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre les deux premiers snapshots\n",
    "t_start = times_sparse[0]\n",
    "t_end = times_sparse[1]\n",
    "X_start = snapshots_sparse[t_start]\n",
    "X_end = snapshots_sparse[t_end]\n",
    "gamma_01 = couplings[(t_start, t_end)]\n",
    "\n",
    "# Calculer plusieurs interpolations\n",
    "t_interp_values = [0.25, 0.5, 0.75]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "# Distribution initiale\n",
    "axes[0].scatter(X_start[:, 0], X_start[:, 1], alpha=0.5, s=10)\n",
    "axes[0].set_title(f't = {t_start:.2f} (source)')\n",
    "axes[0].set_xlabel('$x_0$')\n",
    "axes[0].set_ylabel('$x_1$')\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_xlim(-5, 5)\n",
    "axes[0].set_ylim(-4, 4)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Interpolations\n",
    "for idx, t_frac in enumerate(t_interp_values):\n",
    "    X_interp = mccann_interpolation(X_start, X_end, gamma_01, t_frac, n_samples=1000)\n",
    "    \n",
    "    if X_interp is not None:\n",
    "        axes[idx + 1].scatter(X_interp[:, 0], X_interp[:, 1], alpha=0.5, s=10, color='orange')\n",
    "        t_actual = t_start + t_frac * (t_end - t_start)\n",
    "        axes[idx + 1].set_title(f't = {t_actual:.2f} (interpolé, α={t_frac})')\n",
    "        axes[idx + 1].set_xlabel('$x_0$')\n",
    "        axes[idx + 1].axis('equal')\n",
    "        axes[idx + 1].set_xlim(-5, 5)\n",
    "        axes[idx + 1].set_ylim(-4, 4)\n",
    "        axes[idx + 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution finale\n",
    "axes[4].scatter(X_end[:, 0], X_end[:, 1], alpha=0.5, s=10, color='red')\n",
    "axes[4].set_title(f't = {t_end:.2f} (cible)')\n",
    "axes[4].set_xlabel('$x_0$')\n",
    "axes[4].axis('equal')\n",
    "axes[4].set_xlim(-5, 5)\n",
    "axes[4].set_ylim(-4, 4)\n",
    "axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison avec les vraies distributions intermédiaires\n",
    "\n",
    "Maintenant, comparons les distributions interpolées avec McCann aux **vraies** distributions intermédiaires qu'on a simulées.\n",
    "\n",
    "### 6.1 Mesure de distance : Wasserstein-2\n",
    "\n",
    "Pour quantifier l'écart entre deux distributions empiriques, on va utiliser la distance de Wasserstein-2 (calculée avec OT **non régularisé** cette fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein2_distance(X, Y):\n",
    "    \"\"\"\n",
    "    Calcule la distance de Wasserstein-2 entre deux distributions empiriques.\n",
    "    \n",
    "    Utilise l'OT exact (EMD) pour une mesure précise.\n",
    "    \"\"\"\n",
    "    # TODO: Implémenter le calcul de W2\n",
    "    # Hint: Créer distributions uniformes a, b\n",
    "    # Hint: Calculer matrice de coût C avec 'sqeuclidean'\n",
    "    # Hint: Utiliser ot.emd2 et prendre la racine carrée\n",
    "    # Note: Si EMD échoue, utiliser Sinkhorn avec epsilon petit (1e-3)\n",
    "    \n",
    "    n, m = len(X), len(Y)\n",
    "    \n",
    "    # VOTRE CODE ICI\n",
    "    \n",
    "    return 0.0  # Remplacer par le vrai calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Calcul des erreurs d'interpolation\n",
    "\n",
    "Pour chaque paire de snapshots consécutifs, on va :\n",
    "1. Calculer plusieurs interpolations de McCann à différents temps intermédiaires\n",
    "2. Récupérer les vraies distributions à ces mêmes temps (depuis `snapshots_dense`)\n",
    "3. Mesurer la distance de Wasserstein-2 entre interpolation et vérité terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va tester différentes valeurs d'epsilon\n",
    "epsilon_values = [\n",
    "    epsilon_theory / 5,\n",
    "    epsilon_theory,\n",
    "    epsilon_theory * 5\n",
    "]\n",
    "\n",
    "print(\"Calcul des erreurs d'interpolation pour différents ε...\\n\")\n",
    "\n",
    "# TODO: Calculer les erreurs pour chaque epsilon\n",
    "# Hint: Pour chaque intervalle [t_start, t_end]\n",
    "# Hint: Pour chaque epsilon, calculer le couplage\n",
    "# Hint: Pour chaque temps intermédiaire, calculer l'interpolation de McCann\n",
    "# Hint: Comparer avec la vraie distribution (snapshots_dense)\n",
    "# Hint: Mesurer avec wasserstein2_distance\n",
    "\n",
    "results = {eps: {'times': [], 'errors': []} for eps in epsilon_values}\n",
    "\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "print(\"\\n✓ Évaluation terminée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualisation des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "labels = [f'ε = {eps:.6f}' + (' (théorique)' if np.isclose(eps, epsilon_theory) else '') \n",
    "          for eps in epsilon_values]\n",
    "\n",
    "for eps, color, label in zip(epsilon_values, colors, labels):\n",
    "    times = results[eps]['times']\n",
    "    errors = results[eps]['errors']\n",
    "    \n",
    "    if len(times) > 0:\n",
    "        ax.plot(times, errors, 'o-', color=color, label=label, markersize=6, linewidth=2)\n",
    "\n",
    "# Marquer les temps des snapshots espacés\n",
    "for t in times_sparse:\n",
    "    ax.axvline(t, color='gray', linestyle='--', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_xlabel('Temps t')\n",
    "ax.set_ylabel('Erreur W₂(interpolation, vérité terrain)')\n",
    "ax.set_title('Erreur d\\'interpolation de McCann vs temps\\n(comparaison avec distribution simulée)')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques\n",
    "print(\"\\nStatistiques des erreurs :\")\n",
    "print(\"=\"*70)\n",
    "for eps in epsilon_values:\n",
    "    errors = results[eps]['errors']\n",
    "    if len(errors) > 0:\n",
    "        print(f\"ε = {eps:.6f}:\")\n",
    "        print(f\"  Erreur moyenne : {np.mean(errors):.4f}\")\n",
    "        print(f\"  Erreur médiane : {np.median(errors):.4f}\")\n",
    "        print(f\"  Erreur max     : {np.max(errors):.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Questions de réflexion\n",
    "\n",
    "### Question 1\n",
    "Quelle valeur de $\\varepsilon$ donne la meilleure reconstruction ? Est-ce cohérent avec la théorie ?\n",
    "\n",
    "### Question 2\n",
    "Comment évolue l'erreur au cours du temps ? Y a-t-il des régions temporelles où l'interpolation fonctionne mieux ?\n",
    "\n",
    "### Question 3\n",
    "Que se passe-t-il visuellement quand $\\varepsilon$ est trop petit ou trop grand ?\n",
    "\n",
    "### Question 4\n",
    "Observez-vous un pic d'erreur autour de t ≈ 0.5-0.6 ? Pourquoi ?\n",
    "(Hint: C'est le moment du branchement dans le potentiel complexe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Dans ce notebook, vous avez :\n",
    "\n",
    "✅ Reconstruit des trajectoires par chaînage de couplages OT  \n",
    "✅ Implémenté l'interpolation de McCann  \n",
    "✅ Comparé les interpolations avec les vraies distributions intermédiaires  \n",
    "✅ Mesuré l'erreur de reconstruction via la distance de Wasserstein-2  \n",
    "\n",
    "### Points clés à retenir\n",
    "\n",
    "1. **Interpolation de McCann** : Fournit une façon naturelle et géométriquement fondée d'interpoler entre distributions\n",
    "\n",
    "2. **Choix de $\\varepsilon$** : Le paramètre $\\varepsilon = \\sigma \\Delta t$ n'est pas arbitraire - il découle de la connection avec le problème de Schrödinger\n",
    "\n",
    "3. **Erreur d'interpolation** : Même avec le bon $\\varepsilon$, l'interpolation n'est pas parfaite car le processus sous-jacent n'est pas exactement un transport optimal\n",
    "\n",
    "4. **Branchement** : L'erreur est particulièrement élevée aux points de branchement, ce qui montre les limitations de l'approche\n",
    "\n",
    "### Limitations et perspectives\n",
    "\n",
    "- **Limitation 1** : On a supposé qu'il n'y a pas de branchement (cellules qui se divisent) - mais notre potentiel complexe montre que c'est difficile !\n",
    "- **Limitation 2** : Les distributions observées sont bruitées (peu d'échantillons)\n",
    "\n",
    "→ **Session 2 du TP** : On verra comment optimiser simultanément sur les marginales pour gérer le bruit (gWOT, Chizat et al. 2022)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
